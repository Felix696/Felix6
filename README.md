# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Summary
This dataset contains data about bankmarketting in a csv form. We seek to predict the value of the chosen column(y) which is if there will be a subscription or not.
The best performing model was the model done using the Azure AutoML run. It offers more precise data handling.

## Scikit-learn Pipeline
The pipeline uses a compute cluster with vm size of Standard_d2_v2. The dataset used is created or downloaded from the url providing the bankmarketting form. This data was "cleaned" by configuring the train.py script. It uses classification for its algorithm.  The parameter sample used is RandomParameterSampling. 
Random sampling supports discrete and continuous hyperparameters which could add to the versatility of the sampling. It can support early termination of low-performance runs. The policy used is the BanditPolicy with a slack_factor of 0.1. Accuracy is set as the primary metric. 
This policy terminates runs wherein the primary metric/s is not within the specified slack_factor which it compares from the best performing run. The SKLearn estimator is used and makes use of the train.py as the entry script. 
The hyperparameters called are '--c', which is the regularization paramater, and 'max_iter', which limits the number of iterations allowed. Also the best run model was submitted and saved.


## AutoML
The model generated by AutoML is easy to interpret and hyperparameters can be tuned. Also AutoML makes visible the core features that are driving the model. It automizes the creation of the best model from the data and easily efficiently highlights the best model. The VotingEnsemble is seen as the best model btu the others' accuracy(primay metric shown) is near in value to each other. Parameters like specifying the label_column_name, which is y for the column, experiment_timeout_minutes which is 30 for the timeout in completion of experiment, and the primary metric itself are used for configuration. 

## Pipeline comparison
The AutoML provides a more accurate model since it automatically handles the data. Its best model, VotingEnsemble which is named "amlbankmarket" and id: AutoML_27414687-1351-48c6-8d33-6308a0c78595_36, provides an accuracy of around 91.7328% compared to hyperdrive's 91.4421% with just a small difference of around 0.31%. Though when working on it, more personalitzation could occur with optimizing the pipeline using the scikit-learn. There was a difference in the way of configuration and preparation as automl requires less steps upon automizing.

## Future work
For the hyperdrive, the parameters can still be tweaked, or some can be added, which might provide a much efficent output. Using an AutoML experiment would also provide the best model in the most accessible way. Additionally, the auto ml offers a range of primary metrics that can bring about the best models in an efficient way, try using other primary metrics.  The AutoML output also raises a class imbalance warning about the dataset. For this case, different metrics could reduce this imbalance such as AUC_weighted which Azure supports.

## Proof of cluster clean up
<img src="delete compute.png">
